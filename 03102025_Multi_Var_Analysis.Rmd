---
title: "Multi-Linear Regression but Hierarchical"
output: github_document
editor_options: 
  markdown: 
    wrap: sentence
---

## Table of Contents

-   [Model Summary](#model-summary)
-   [Estimates](#estimates)
-   [Diagnostics](#diagnostics)
-   [Interpretation](#interpretation)
-   [Model Fit Tests](#model-fit-tests)
-   [PAC Behavior Summary](#pac-behavior-summary)

```{r message=FALSE}
library(readxl)
library(dplyr)
library(ggplot2)
library(tidyr)
library(rstanarm)
library(FactoMineR)
library(factoextra)
library(cluster)
library(brms)
library(rstudioapi)
library(cmdstanr)
library(ggplot2)
library(tidybayes)
```

## Brief Introduction into the Data

Slight modification as previous data set was corrupted, we have moved to analyzing the bill 'SUSTAIN Care Act of 2018; Family First Prevention Services Act'

```{r}
# Load the Excel file
file_path <- "D:/SUSTAIN_Votes_Merged.xlsx"
df <- read_excel(file_path, sheet = "SUSTAIN_Votes_Merged")

# View first few rows
head(df)
```

```{r}
# Convert Vote_tax to numeric (1 = Yea, 0 = Nay)
df$Vote_numeric <- ifelse(df$Vote == "Yea", 1, ifelse(df$Vote == "Nay", 0, NA))

# Remove NA values before bootstrapping
valid_votes <- df$Vote_numeric[!is.na(df$Vote_numeric)]
# Convert categorical to factors if needed

# Histogram for Contribution Amount
ggplot(df, aes(x = Contribution_Amount)) +
  geom_histogram(bins = 30, fill = "blue", alpha = 0.6) +
  labs(title = "Distribution of Contribution Amounts",
       x = "Contribution Amount",
       y = "Frequency")

# Boxplot grouped by Vote on Tax Bill
ggplot(df, aes(x = Vote, y = Contribution_Amount, fill = Vote)) +
  geom_boxplot() +
  labs(title = "Contributions by Tax Vote",
       x = "Vote on Tax",
       y = "Contribution Amount")

```

------------------------------------------------------------------------

## Create Contribution Matrix for PCA & Clustering

```{r}

# Pivot table: PACs (rows) Ã— Senators (cols)
contrib_matrix <- df %>%
  group_by(PAC_Name, Senator_ID) %>%
  summarise(Total = sum(Contribution_Amount, na.rm = TRUE), .groups = "drop") %>%
  pivot_wider(names_from = Senator_ID, values_from = Total, values_fill = 0)

# Save PAC names separately
pac_names <- contrib_matrix$PAC_Name
contrib_matrix <- contrib_matrix %>% select(-PAC_Name)
```

## PCA and KMeans Clustering

```{r}
# Run PCA
pca_res <- PCA(contrib_matrix, graph = FALSE)
pc_df <- as.data.frame(pca_res$ind$coord[, 1:2])
colnames(pc_df) <- c("PC1", "PC2")
pc_df$PAC_Name <- pac_names

# KMeans clustering (k = 4)
set.seed(42)
kmeans_res <- kmeans(contrib_matrix, centers = 4)
pc_df$Cluster_k4 <- kmeans_res$cluster

df <- df %>%
  left_join(pc_df, by = "PAC_Name")

```

## Multi-Regression Model

```{r}
# Aggregate total PAC contributions per senator
df$Log_Contribution <- log1p(df$Contribution_Amount)

model <- stan_glm(Vote_numeric ~ Log_Contribution + PC1 + PC2 + Party , data = df, family = binomial(link = "logit"), algorithm = "optimizing", tol_rel_grad = 1e-10) 

summary(model)

df$Cluster_k4 <- as.factor(df$Cluster_k4)

model2 <- stan_glm(Vote_numeric ~ Log_Contribution + Cluster_k4 + Party , data = df, family = binomial(link = "logit"), algorithm = "optimizing", tol_rel_grad = 1e-10) 
summary(model2)

model3 <- stan_glm(Vote_numeric ~ Log_Contribution + Cluster_k4 + PC1 + PC2 + Party , data = df, family = binomial(link = "logit"), algorithm = "optimizing", tol_rel_grad = 1e-10) 
summary(model3)

```

# Hierarchical model with varying intercepts for PACs

```{r}
model_hier <- brm(
  Vote_numeric ~ Log_Contribution + PC1 + PC2 + Party + (1 | Cluster_k4),
  data = df,
  family = bernoulli(),
  backend = "cmdstanr",        # Way faster and better diagnostics
  algorithm = "fullrank",      # Still variational, but better than meanfield
  iter = 30000,
  tol_rel_obj = 0.001
)

summary(model_hier)
```

## Plots

```{r}

# Posterior predictive check
pp_check(model_hier, plotfun = "hist", nreps = 100)

ranef(model_hier)$Cluster_k4

plot(conditional_effects(model_hier, effects = 'Log_Contribution', 'PC1', 'PC2'))


```

## Diagnostic Test and Interpretation

To evaluate the fit of our Bayesian logistic regression model, we conducted a **posterior predictive check** using the pp_check() function with dens_overlay, as recommended in Section 11.4 of *Regression and Other Stories*.
This method compares the distribution of the observed vote outcomes with the distribution of outcomes simulated from the model's posterior predictive distribution.
Using 10 draws from the posterior, we examined the overlap between the empirical and simulated densities.
While the central distribution of the simulated data aligned reasonably well with the observed data, the summary statistics suggest small deviations in the tails, as indicated by the estimates and credible intervals.
These differences likely reflect some mild underfitting in the areas with extreme values or uncertainty about rare voting behavior types.
However, the general shape and location of the distributions suggest that the model captures the dominant patterns in the data.
This diagnostic supports the validity of the model while also highlighting areas for potential refinement, especially in handling outliers or incorporating varying dispersion across clusters.

### **Model Deviations from the Minimal Adjustment Set**

The minimal adjustment set for this study, based on a theoretical DAG of causal influence, likely includes PAC contribution amount and party affiliation as core confounders that must be controlled to estimate the effect of contributions on vote outcomes.
However, we chose to extend the final model beyond this minimal set by including PCA components (PC1 and PC2) and a varying intercept for PAC behavior clusters.
These additions introduce latent structure to account for strategic differences in PAC targeting behavior that are not explicitly captured by party or contribution amount alone.
The inclusion of these terms improves model fit and helps address potential post-treatment bias or unmeasured confounding by modeling the heterogeneity in PAC strategies.
While this deviates from the strict minimal set, the consequences are beneficial rather than problematic: these additions reduce residual confounding, improve predictive performance, and make the causal estimate of contributions more robust under plausible behavioral structures.

## Labeling PAC Clusters

```{r}
label_pac_clusters_behaviorally <- function(df, return_labeled_data = TRUE) {
 

  # Step 1: Summarize PAC cluster behavior
  cluster_summary <- df %>%
    group_by(Cluster_k4) %>%
    summarise(
      Total_Contributions = sum(Contribution_Amount, na.rm = TRUE),
      Avg_Contribution = mean(Contribution_Amount, na.rm = TRUE),
      Yea_Rate = mean(Vote_numeric, na.rm = TRUE),
      .groups = "drop"
    )

  # Step 2: Calculate thresholds *before* assigning labels
  avg_q3 <- quantile(cluster_summary$Avg_Contribution, 0.75, na.rm = TRUE)
  yea_q1 <- quantile(cluster_summary$Yea_Rate, 0.25, na.rm = TRUE)
  yea_q3 <- quantile(cluster_summary$Yea_Rate, 0.75, na.rm = TRUE)

  # Step 3: Assign labels based on patterns
  cluster_summary <- cluster_summary %>%
    mutate(
      Cluster_Label = case_when(
        Avg_Contribution >= avg_q3 ~ "Strategic Leadership PACs",
        Yea_Rate <= yea_q1 ~ "Low-Yea Vote PACs",
        Yea_Rate >= yea_q3 ~ "High-Yea Vote PACs",
        TRUE ~ "Moderate / Niche PACs"
      )
    )

  print(cluster_summary)

  # Step 4: Join back to full dataset
  if (return_labeled_data) {
    df <- df %>%
      left_join(cluster_summary %>% select(Cluster_k4, Cluster_Label), by = "Cluster_k4")
    return(df)
  } else {
    return(cluster_summary)
  }
}
df <- label_pac_clusters_behaviorally(df)

table(df$Cluster_Label)
```

```{r}
label_pacs_by_pca_quadrant <- function(df) {
  

  # Calculate median cutoffs
  pc1_med <- median(df$PC1, na.rm = TRUE)
  pc2_med <- median(df$PC2, na.rm = TRUE)

  df <- df %>%
    mutate(
      PCA_Quadrant_Label = case_when(
        PC1 >= pc1_med & PC2 >= pc2_med ~ "Pro-Bill Strategic",
        PC1 >= pc1_med & PC2 <  pc2_med ~ "Pro-Bill Minimalist",
        PC1 <  pc1_med & PC2 >= pc2_med ~ "Opposition Strategic",
        PC1 <  pc1_med & PC2 <  pc2_med ~ "Opposition Minimalist",
        TRUE ~ "Unclassified"
      )
    )

  # Show PAC count per label
  cat("PAC Behavior by PCA Quadrant:\n")
  print(table(df$PCA_Quadrant_Label))

  return(df)
}
df <- label_pacs_by_pca_quadrant(df)


```

## Results Interpretation

This study employed a hierarchical Bayesian logistic regression to analyze the relationship between Political Action Committee (PAC) contributions and senator voting behavior on the SUSTAIN Care Act and associated legislation.
The model included fixed effects for log-transformed contribution amounts, PCA-derived dimensions of PAC behavior (PC1 and PC2), and party affiliation, with varying intercepts by PAC cluster to account for latent structure in PAC strategy and identity.

## Fixed Effects

The coefficient for log-transformed contributions (Estimate = 0.31, 95% CI: [0.30, 0.33]) indicates a positive and statistically significant relationship between contribution size and the probability of a "Yea" vote.
This effect persists even after controlling for partisan affiliation and PAC behavior clusters, suggesting that financial contributions are not merely endogenous to party but exert an independent influence on legislative support.
Party affiliation remains a dominant predictor.
Republican senators are significantly less likely to vote in favor of the bill, as reflected by the negative coefficient on PartyR (Estimate = -1.46, 95% CI: [-1.51, -1.40]).
This aligns with expectations given the ideological valence of the bill and the partisan split in the Senate at the time.

The first principal component (PC1), representing the pro-bill vs. opposition dimension of PAC behavior, also exerts a slight but positive effect (Estimate = 0.01).
The second component (PC2), which appears to capture variance orthogonal to the pro/anti-bill axis (e.g., issue intensity or sector specificity), is not statistically significant.

## Random Effects

Varying Intercepts by PAC Cluster Introducing varying intercepts by PAC behavioral clusters improves the model's ability to account for unobserved heterogeneity in strategic PAC behavior.
The standard deviation of the intercepts across the four clusters is estimated at 0.51, indicating meaningful variance in baseline voting propensity across these PAC types.

-   High-Yea Vote PACs: These PACs consistently support the bill.
    Senators receiving contributions from these PACs show a higher baseline probability of voting in favor.

-   Low-Yea Vote PACs: These PACs contribute to senators who largely oppose the bill, suggesting alignment with ideological opposition.

-   Moderate/Niche PACs: These exhibit mixed behavior, possibly reflecting issue specialization or bipartisan targeting.

-   Strategic Leadership PACs: These PACs appear to target influential senators regardless of expected vote, suggesting a longer-term or reputational strategy.

## Behavioral Quadrants

PCA quadrants were interpreted as:

-   Opposition Minimalist: Sparse contributions with low alignment to the bill.

-   Opposition Strategic: Focused opposition contributions, possibly targeting swing votes.

-   Pro-Bill Minimalist: Low-volume but supportive contributors.

-   Pro-Bill Strategic: High-volume contributors to pro-bill senators, potentially influencing outcomes.

PACs clustered within these behavioral types show markedly different strategies, with Strategic Leadership PACs and Pro-Bill Strategic PACs emerging as particularly consequential for predicting "Yea" votes.
